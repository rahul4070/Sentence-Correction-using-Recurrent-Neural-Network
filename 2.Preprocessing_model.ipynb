{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OqTzSLxfXir",
    "outputId": "5a9dca8a-a3fc-4d69-85f1-c1a9b42a8f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dyRdD_H7OWFn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "OelMYg-7M-Zg",
    "outputId": "7224ba15-3703-4d16-92c9-7fb493665842"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text                                       english_text\n",
       "0                  U wan me to \"chop\" seat 4 u nt?\\n   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                          I'm thai. what do u do?\\n                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataframe from disk\n",
    "\n",
    "data = pd.read_csv('/content/drive/MyDrive/seq2seq/data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdUagrkbksfy"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KDqaRrkkroE",
    "outputId": "cc3c93be-6b38-475f-f4b5-8c41fed3095b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.7-py3-none-any.whl (405 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▉                               | 10 kB 25.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 20 kB 30.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 30 kB 12.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 40 kB 9.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 51 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 61 kB 5.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 71 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 81 kB 6.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 92 kB 4.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 102 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 112 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 122 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 133 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 143 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 153 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 163 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 174 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 184 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 194 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 204 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 215 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 225 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 235 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 245 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 256 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 266 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 276 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 286 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 296 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 307 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 317 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 327 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 337 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 348 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 358 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 368 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 378 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 389 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 399 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 405 kB 5.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: nlpaug\n",
      "Successfully installed nlpaug-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fr8dVqAQoEco"
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.char as nac\n",
    "from nlpaug.util.file.download import DownloadUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TF85yx4_okzu"
   },
   "outputs": [],
   "source": [
    "model_dir = '/content/'\n",
    "DownloadUtil.download_glove('glove.6B', '/content/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I89fScrqC8Nb",
    "outputId": "8e2643d4-be33-434c-fdbe-5deee865e23d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enCDmlnytQ83"
   },
   "outputs": [],
   "source": [
    "# reference: https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
    "\n",
    "aug_key_char = nac.KeyboardAug()\n",
    "\n",
    "# aug_insert = naw.WordEmbsAug(\n",
    "#     model_type='glove', model_path=model_dir+'glove.6B.300d.txt',\n",
    "#     action=\"insert\")\n",
    "\n",
    "aug_substitute = naw.WordEmbsAug(\n",
    "    model_type='glove', model_path=model_dir+'glove.6B.300d.txt',\n",
    "    action=\"substitute\")\n",
    "\n",
    "aug_synonym = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxDfZUo9z7E3",
    "outputId": "6d2c6fa1-63ac-4a6c-89b8-caa45116ece6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [14:59<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "aug_char_dist = list()\n",
    "# aug_text_insert = list()\n",
    "aug_text_substitute = list()\n",
    "aug_text_synonym = list()\n",
    "\n",
    "for text in tqdm(data.english_text.values):\n",
    "    aug_char_dist.append(aug_key_dist.augment(text))\n",
    "    # aug_text_insert.append(aug_insert.augment(text))\n",
    "    aug_text_substitute.append(aug_substitute.augment(text))\n",
    "    aug_text_synonym.append(aug_synonym.augment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "wGKyId5Jz6g2",
    "outputId": "16f656aa-2f9e-4fe6-e1ec-ef0a3b2847f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do thing want me to reserve re-elected for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeap. You higher? We announced some Durian pas...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become but expensive although. Mine appea...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ' j Thai. What even can do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your tuesday go? Haven ' shorts he...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text                                       english_text\n",
       "0  Do thing want me to reserve re-elected for you...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yeap. You higher? We announced some Durian pas...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become but expensive although. Mine appea...  They become more expensive already. Mine is li...\n",
       "3                      I ' j Thai. What even can do?                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your tuesday go? Haven ' shorts he...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_df = pd.DataFrame(list(zip(aug_char_dist, data.english_text.values)), columns=['corrupted_text', 'english_text'])\n",
    "text_substitute_df = pd.DataFrame(list(zip(aug_text_substitute, data.english_text.values)), columns=['corrupted_text', 'english_text'])\n",
    "synonym_df = pd.DataFrame(list(zip(aug_text_synonym, data.english_text.values)), columns=['corrupted_text', 'english_text'])\n",
    "\n",
    "df = pd.concat([text_substitute_df, synonym_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "kynZ-E_WWXKa",
    "outputId": "aca7d0d1-dbb7-4134-dd22-df84304ccb5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text                                       english_text\n",
       "0                  U wan me to \"chop\" seat 4 u nt?\\n   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                          I'm thai. what do u do?\\n                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.concat([data, df])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnsVoBIkWen7"
   },
   "outputs": [],
   "source": [
    "# saving the file to disk\n",
    "# data_df.to_csv('/content/drive/MyDrive/seq2seq/data_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC-4AV8Hu7lY"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ofepRZZ3_S8L"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('/content/drive/MyDrive/seq2seq/data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jx0S0zgaNo9x"
   },
   "outputs": [],
   "source": [
    "# reference: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JMTXb_iiwF6M"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "        Function to clean the strings containing special characters and converts them to lowercase characters.\n",
    "\n",
    "        input: string\n",
    "        output: string which contains number and lower character.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert the string to lowercase\n",
    "    text = text.lower()\n",
    "    # decontraction - expanding the words like : i'll -> i will, he'd -> he would\n",
    "    text = decontracted(text)\n",
    "    text = re.sub('[^A-Za-z0-9]',' ',text)\n",
    "    text = re.sub('\\s_\\s', ' ', text)   #  replace strings like  ' _ ' with ' ' (string with a space)\n",
    "    text = re.sub('\\s+', ' ', text).strip()  # replace more than one_space_character to single_space_character\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTeWfmih7gLB",
    "outputId": "1ee2f972-4aa0-4d12-b5ec-f2935ac47711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:00<00:00, 33458.78it/s]\n",
      "100%|██████████| 6000/6000 [00:00<00:00, 37080.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "\n",
    "tqdm.pandas()\n",
    "data_df['corrupted_text'] = data_df['corrupted_text'].progress_apply(preprocess)\n",
    "data_df['english_text']   = data_df['english_text'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "BTBcdbqSJ5bp",
    "outputId": "2b25d250-e532-48c3-9547-e87b2a48310c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u wan me to chop seat 4 u nt</td>\n",
       "      <td>do you want me to reserve seat for you or not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yup u reaching we order some durian pastry alr...</td>\n",
       "      <td>yeap you reaching we ordered some durian pastr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they become more ex oredi mine is like 25 so h...</td>\n",
       "      <td>they become more expensive already mine is lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am thai what do u do</td>\n",
       "      <td>i am thai what do you do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi how did your week go haven heard from you f...</td>\n",
       "      <td>hi how did your week go have not heard from yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text                                       english_text\n",
       "0                       u wan me to chop seat 4 u nt      do you want me to reserve seat for you or not\n",
       "1  yup u reaching we order some durian pastry alr...  yeap you reaching we ordered some durian pastr...\n",
       "2  they become more ex oredi mine is like 25 so h...  they become more expensive already mine is lik...\n",
       "3                             i am thai what do u do                           i am thai what do you do\n",
       "4  hi how did your week go haven heard from you f...  hi how did your week go have not heard from yo..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FghiAPDIm8e8"
   },
   "outputs": [],
   "source": [
    "# shuffling the dataframe \n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3xWOBZMyljq"
   },
   "source": [
    "## Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "M73Ayaiv1fEx"
   },
   "outputs": [],
   "source": [
    "english_text_inp = '<start> ' + data_df['english_text'].astype(str)\n",
    "english_text_out = data_df['english_text'].astype(str) + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gtbZrAx21iIG"
   },
   "outputs": [],
   "source": [
    "data_df['english_inp'] = english_text_inp\n",
    "data_df['english_out'] = english_text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DZLgG-zV6I8J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data_df, test_size=0.1)\n",
    "train, test = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IJSMAGKC5Lng"
   },
   "outputs": [],
   "source": [
    "# we are doing the below step to add '<end>' to the tokenizer dictionary\n",
    "\n",
    "train.iloc[0]['english_inp'] = train.iloc[0]['english_inp'] + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2r7MYeLyx8zh"
   },
   "outputs": [],
   "source": [
    "tknizer_corr = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_corr.fit_on_texts(train['corrupted_text'].values)\n",
    "\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pC0IUPOCSG5P",
    "outputId": "570070a7-c611-4310-a620-27c1a26f9049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n",
      "7590\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_corr=len(tknizer_corr.word_index.keys())\n",
    "print(vocab_size_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "o716mAwZx6yL"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_corr, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['corrupted_text'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_corr = tknizer_corr\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_corr.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3k4_n9Ltx6t_",
    "outputId": "a13038b1-d065-4851-d6c4-22c083aa88e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50) (100, 50) (100, 50)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_corr, tknizer_eng, 50)\n",
    "validation_dataset  = Dataset(validation, tknizer_corr, tknizer_eng, 50)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=100)\n",
    "validation_dataloader = Dataloder(validation_dataset, batch_size=100)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3rJnOnLomNP"
   },
   "source": [
    "## Encoder Decoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbvrO8Jcx6op",
    "outputId": "0f5b4445-2e78-4ddf-f3d7-e50990029557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_encoder (Embedd (None, None, 50)     379550      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_decoder (Embedd (None, None, 100)    298900      decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, None, 124),  86800       embedding_layer_encoder[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 124),  111600      embedding_layer_decoder[0][0]    \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2989)   373625      Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,250,475\n",
      "Trainable params: 1,250,475\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder setup\n",
    "encoder_input = Input(shape=(None, ), name='encoder_input')\n",
    "embedding_encoder = Embedding(input_dim=vocab_size_corr + 1 , output_dim=50 , mask_zero=True , name='embedding_layer_encoder')(encoder_input)\n",
    "lstm_encoder, state_h, state_c = LSTM(124  , return_state=True, return_sequences=True, name='Encoder_LSTM')(embedding_encoder)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder setup\n",
    "decoder_input = Input(shape=(None, ), name='decoder_input')\n",
    "embedding_output = Embedding(input_dim=vocab_size_eng + 1 , output_dim=100 ,mask_zero= True, name='embedding_layer_decoder')\n",
    "decoder_embedding = embedding_output(decoder_input)\n",
    "\n",
    "lstm_decoder = LSTM(124 , return_state=True, return_sequences=True, name='Decoder_LSTM')\n",
    "decoder_output, _, _ = lstm_decoder(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size_eng + 1 , activation='softmax'))\n",
    "dense_layer = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], dense_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXeSgNfqx6eQ",
    "outputId": "2002091b-7aa3-4b87-a4df-e7547dc4e3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "filepath = '/content/drive/MyDrive/seq2seq/checkpoint/model_1/weights-{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=0, save_best_only=True, mode=\"auto\")\n",
    "\n",
    "# log_dir = '/content/drive/MyDrive/seq2seq/logs/model_1/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir=\"/content/drive/MyDrive/seq2seq/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuEjFQIcdsRh",
    "outputId": "2bff6d95-f584-4e72-a0a9-baa9a115eca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4860, 4), (600, 4), (540, 4))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWRh-lAxx6UM",
    "outputId": "a4ca59d8-c2ef-42ad-d014-aab1da52b45b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 20s 195ms/step - loss: 2.2341 - accuracy: 0.0663 - val_loss: 1.8864 - val_accuracy: 0.0659\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.8264 - accuracy: 0.0800 - val_loss: 1.8605 - val_accuracy: 0.0823\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.7942 - accuracy: 0.0984 - val_loss: 1.8377 - val_accuracy: 0.1037\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.7924 - accuracy: 0.1068 - val_loss: 1.8104 - val_accuracy: 0.1018\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.7457 - accuracy: 0.1092 - val_loss: 1.7806 - val_accuracy: 0.1045\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.7112 - accuracy: 0.1105 - val_loss: 1.7632 - val_accuracy: 0.1099\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.7182 - accuracy: 0.1137 - val_loss: 1.7513 - val_accuracy: 0.1143\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.6896 - accuracy: 0.1155 - val_loss: 1.7418 - val_accuracy: 0.1157\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.6864 - accuracy: 0.1176 - val_loss: 1.7291 - val_accuracy: 0.1176\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.6732 - accuracy: 0.1198 - val_loss: 1.7174 - val_accuracy: 0.1200\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 1.6661 - accuracy: 0.1248 - val_loss: 1.7051 - val_accuracy: 0.1294\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 1.6474 - accuracy: 0.1347 - val_loss: 1.6906 - val_accuracy: 0.1348\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.6263 - accuracy: 0.1390 - val_loss: 1.6732 - val_accuracy: 0.1422\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.6046 - accuracy: 0.1446 - val_loss: 1.6612 - val_accuracy: 0.1439\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.5691 - accuracy: 0.1520 - val_loss: 1.6420 - val_accuracy: 0.1496\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.5692 - accuracy: 0.1559 - val_loss: 1.6249 - val_accuracy: 0.1534\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 1.5443 - accuracy: 0.1656 - val_loss: 1.6070 - val_accuracy: 0.1666\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.5290 - accuracy: 0.1769 - val_loss: 1.5867 - val_accuracy: 0.1797\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.4995 - accuracy: 0.1890 - val_loss: 1.5727 - val_accuracy: 0.1859\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 1.4878 - accuracy: 0.1973 - val_loss: 1.5540 - val_accuracy: 0.1950\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 1.4588 - accuracy: 0.2047 - val_loss: 1.5405 - val_accuracy: 0.1991\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.4549 - accuracy: 0.2075 - val_loss: 1.5254 - val_accuracy: 0.2013\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 1.4364 - accuracy: 0.2114 - val_loss: 1.5163 - val_accuracy: 0.2037\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.4086 - accuracy: 0.2166 - val_loss: 1.5026 - val_accuracy: 0.2067\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.3995 - accuracy: 0.2209 - val_loss: 1.4898 - val_accuracy: 0.2092\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.3753 - accuracy: 0.2244 - val_loss: 1.4758 - val_accuracy: 0.2089\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.3721 - accuracy: 0.2277 - val_loss: 1.4666 - val_accuracy: 0.2131\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.3515 - accuracy: 0.2324 - val_loss: 1.4559 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 1.3362 - accuracy: 0.2345 - val_loss: 1.4450 - val_accuracy: 0.2172\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 1.3271 - accuracy: 0.2375 - val_loss: 1.4346 - val_accuracy: 0.2184\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.3134 - accuracy: 0.2425 - val_loss: 1.4279 - val_accuracy: 0.2199\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.3036 - accuracy: 0.2457 - val_loss: 1.4204 - val_accuracy: 0.2226\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.2923 - accuracy: 0.2499 - val_loss: 1.4058 - val_accuracy: 0.2243\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.2718 - accuracy: 0.2543 - val_loss: 1.4002 - val_accuracy: 0.2288\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.2541 - accuracy: 0.2599 - val_loss: 1.3882 - val_accuracy: 0.2292\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.2388 - accuracy: 0.2618 - val_loss: 1.3813 - val_accuracy: 0.2308\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 1.2385 - accuracy: 0.2656 - val_loss: 1.3708 - val_accuracy: 0.2333\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.2209 - accuracy: 0.2690 - val_loss: 1.3628 - val_accuracy: 0.2346\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.2012 - accuracy: 0.2752 - val_loss: 1.3544 - val_accuracy: 0.2385\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.1872 - accuracy: 0.2784 - val_loss: 1.3413 - val_accuracy: 0.2422\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.1645 - accuracy: 0.2834 - val_loss: 1.3325 - val_accuracy: 0.2453\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.1648 - accuracy: 0.2868 - val_loss: 1.3233 - val_accuracy: 0.2480\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 3s 87ms/step - loss: 1.1539 - accuracy: 0.2922 - val_loss: 1.3174 - val_accuracy: 0.2545\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 1.1375 - accuracy: 0.2959 - val_loss: 1.3096 - val_accuracy: 0.2545\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.1255 - accuracy: 0.3013 - val_loss: 1.3038 - val_accuracy: 0.2563\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.1122 - accuracy: 0.3044 - val_loss: 1.2935 - val_accuracy: 0.2571\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.1065 - accuracy: 0.3098 - val_loss: 1.2809 - val_accuracy: 0.2642\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.0839 - accuracy: 0.3162 - val_loss: 1.2730 - val_accuracy: 0.2658\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.0677 - accuracy: 0.3221 - val_loss: 1.2628 - val_accuracy: 0.2704\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.0746 - accuracy: 0.3247 - val_loss: 1.2544 - val_accuracy: 0.2731\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.0593 - accuracy: 0.3323 - val_loss: 1.2488 - val_accuracy: 0.2770\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.0273 - accuracy: 0.3389 - val_loss: 1.2395 - val_accuracy: 0.2770\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.0169 - accuracy: 0.3437 - val_loss: 1.2289 - val_accuracy: 0.2798\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.0189 - accuracy: 0.3464 - val_loss: 1.2198 - val_accuracy: 0.2871\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.9982 - accuracy: 0.3530 - val_loss: 1.2167 - val_accuracy: 0.2868\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 1.0012 - accuracy: 0.3595 - val_loss: 1.2101 - val_accuracy: 0.2902\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.9691 - accuracy: 0.3653 - val_loss: 1.2073 - val_accuracy: 0.2926\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.9744 - accuracy: 0.3697 - val_loss: 1.1976 - val_accuracy: 0.2973\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.9506 - accuracy: 0.3775 - val_loss: 1.1876 - val_accuracy: 0.3029\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.9354 - accuracy: 0.3829 - val_loss: 1.1776 - val_accuracy: 0.3049\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.9283 - accuracy: 0.3877 - val_loss: 1.1807 - val_accuracy: 0.3052\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.9220 - accuracy: 0.3929 - val_loss: 1.1680 - val_accuracy: 0.3093\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.9103 - accuracy: 0.4004 - val_loss: 1.1581 - val_accuracy: 0.3120\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.8913 - accuracy: 0.4079 - val_loss: 1.1546 - val_accuracy: 0.3153\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.8946 - accuracy: 0.4101 - val_loss: 1.1446 - val_accuracy: 0.3204\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.8741 - accuracy: 0.4194 - val_loss: 1.1410 - val_accuracy: 0.3205\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.8638 - accuracy: 0.4251 - val_loss: 1.1329 - val_accuracy: 0.3230\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.8487 - accuracy: 0.4322 - val_loss: 1.1277 - val_accuracy: 0.3245\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.8399 - accuracy: 0.4398 - val_loss: 1.1239 - val_accuracy: 0.3268\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.8380 - accuracy: 0.4460 - val_loss: 1.1192 - val_accuracy: 0.3284\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.8241 - accuracy: 0.4502 - val_loss: 1.1117 - val_accuracy: 0.3308\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.8148 - accuracy: 0.4538 - val_loss: 1.1038 - val_accuracy: 0.3350\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.8039 - accuracy: 0.4611 - val_loss: 1.1000 - val_accuracy: 0.3364\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.7907 - accuracy: 0.4684 - val_loss: 1.0949 - val_accuracy: 0.3371\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 0.7806 - accuracy: 0.4751 - val_loss: 1.0890 - val_accuracy: 0.3396\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.7740 - accuracy: 0.4808 - val_loss: 1.0852 - val_accuracy: 0.3391\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.7577 - accuracy: 0.4871 - val_loss: 1.0790 - val_accuracy: 0.3446\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.7573 - accuracy: 0.4912 - val_loss: 1.0735 - val_accuracy: 0.3434\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.7442 - accuracy: 0.4978 - val_loss: 1.0752 - val_accuracy: 0.3481\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.7383 - accuracy: 0.4992 - val_loss: 1.0670 - val_accuracy: 0.3505\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.7263 - accuracy: 0.5043 - val_loss: 1.0640 - val_accuracy: 0.3509\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.7312 - accuracy: 0.5067 - val_loss: 1.0465 - val_accuracy: 0.3542\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.7135 - accuracy: 0.5142 - val_loss: 1.0416 - val_accuracy: 0.3566\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.7086 - accuracy: 0.5186 - val_loss: 1.0476 - val_accuracy: 0.3591\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.6961 - accuracy: 0.5254 - val_loss: 1.0280 - val_accuracy: 0.3662\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 0.6828 - accuracy: 0.5348 - val_loss: 1.0279 - val_accuracy: 0.3664\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.6781 - accuracy: 0.5399 - val_loss: 1.0197 - val_accuracy: 0.3669\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.6660 - accuracy: 0.5454 - val_loss: 1.0242 - val_accuracy: 0.3705\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.6605 - accuracy: 0.5531 - val_loss: 1.0161 - val_accuracy: 0.3717\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.6509 - accuracy: 0.5545 - val_loss: 1.0097 - val_accuracy: 0.3746\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.6418 - accuracy: 0.5612 - val_loss: 1.0044 - val_accuracy: 0.3754\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.6368 - accuracy: 0.5658 - val_loss: 1.0009 - val_accuracy: 0.3787\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.6321 - accuracy: 0.5697 - val_loss: 0.9997 - val_accuracy: 0.3814\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.6272 - accuracy: 0.5754 - val_loss: 0.9976 - val_accuracy: 0.3809\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.6089 - accuracy: 0.5799 - val_loss: 0.9874 - val_accuracy: 0.3864\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 3s 84ms/step - loss: 0.6058 - accuracy: 0.5875 - val_loss: 0.9843 - val_accuracy: 0.3888\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.6023 - accuracy: 0.5897 - val_loss: 0.9917 - val_accuracy: 0.3897\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.5995 - accuracy: 0.5951 - val_loss: 0.9734 - val_accuracy: 0.3929\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 0.5810 - accuracy: 0.6027 - val_loss: 0.9759 - val_accuracy: 0.3937\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.5823 - accuracy: 0.6061 - val_loss: 0.9732 - val_accuracy: 0.3963\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_steps=train.shape[0]//128\n",
    "valid_steps=validation.shape[0]//128\n",
    "\n",
    "model_history1=model.fit_generator(train_dataloader,steps_per_epoch=train_steps,epochs=100, validation_data=validation_dataloader, validation_steps=valid_steps,\n",
    "                                   callbacks=[\n",
    "                                              model_checkpoint, \n",
    "                                              tensorboard_callback\n",
    "                                              ]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzBbuI3jBasD"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ehk7IOry7yiy"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_input, encoder_states)\n",
    "\n",
    "decoder_state_h = Input(shape=(None,), name='decoder_state_h')\n",
    "decoder_state_c = Input(shape=(None,), name='decoder_state_c')\n",
    "decoder_states = [decoder_state_h, decoder_state_c]\n",
    "\n",
    "decoder_embed = embedding_output(decoder_input)\n",
    "decoder_lstm, state_h_, state_c_ = lstm_decoder(decoder_embed, initial_state=decoder_states)\n",
    "decoder_state_out = [state_h_, state_c_]\n",
    "decoder_out = model.layers[6](decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdIN-Lef7yfC",
    "outputId": "cd8b05d2-5944-442a-8195-9f341b32bcd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_decoder (Embedd (None, None, 100)    298900      decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_state_h (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_state_c (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             multiple             111600      embedding_layer_decoder[1][0]    \n",
      "                                                                 decoder_state_h[0][0]            \n",
      "                                                                 decoder_state_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2989)   373625      Decoder_LSTM[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 784,125\n",
      "Trainable params: 784,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model([decoder_input] + decoder_states, [decoder_out] + decoder_state_out)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Vv2HcAnO7xyS"
   },
   "outputs": [],
   "source": [
    "def inference(sequence):\n",
    "    inp_seq = tknizer_corr.texts_to_sequences([sequence])\n",
    "    inp_seq = pad_sequences(inp_seq, maxlen=50, dtype='int32', padding='post')\n",
    "\n",
    "    inp_seq = inp_seq.reshape(-1,50)\n",
    "    encoder_states = encoder_model.predict(inp_seq)\n",
    "\n",
    "    target = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
    "    pred = []\n",
    "    for i in range(20):\n",
    "        output, state_h, state_c = decoder_model([target]+encoder_states)\n",
    "        encoder_states = [state_h, state_c]\n",
    "        target = np.reshape(np.argmax(output), (1, 1))\n",
    "        pred.append(tknizer_eng.index_word[target[0][0]])\n",
    "        if(pred[-1]=='<end>'):\n",
    "            break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "IlbESY8ogMeg"
   },
   "outputs": [],
   "source": [
    "t = test.corrupted_text.values[0:10]\n",
    "l = test.english_text.values[0:10]\n",
    "s = list()\n",
    "for i in t:\n",
    "    k = inference(i)\n",
    "    s.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGMinZpXhDm5",
    "outputId": "5f671e93-ebbe-4d76-8bfd-fd0e4e448720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    :- yup hehe you like then good hehe\n",
      "predicted :- yes it is it to buy newspaper <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- i think i do not want the glasses seldom use it anyway save some money hee\n",
      "predicted :- i will be late have not ask her to wait for rebecca she is not <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- i think the chinese tester is better\n",
      "predicted :- i am going to claim vat <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- no i am going to the wrks with j what about you\n",
      "predicted :- no i am not going to school then can you be with <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- what time will you end then we are at og\n",
      "predicted :- what time will you be at home <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- relax it is easy i am fine thanks my friends are asking me out but i do not know what to do now so boring\n",
      "predicted :- i am in imperialmusic listening to the weirdest track ever by leafcutter john sounds like insects being molested and someone\n",
      "--------------------\n",
      "\n",
      "actual    :- hi kote and maxy please give me your introduction and telephone number my number is 0166305681\n",
      "predicted :- hi girl can you message me your hand phone number i am in town so boring <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- after your work do not know where town\n",
      "predicted :- anything to go for dinner <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- sorry i did not know you called we are not having dinner together maybe meet another day take care\n",
      "predicted :- sorry i have got to be a few days if you are going out for you <end>\n",
      "--------------------\n",
      "\n",
      "actual    :- we reach already\n",
      "predicted :- he is at penisula <end>\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('actual    :-', l[i])\n",
    "    print('predicted :-', s[i])\n",
    "    print('-' * 20)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing.txt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
