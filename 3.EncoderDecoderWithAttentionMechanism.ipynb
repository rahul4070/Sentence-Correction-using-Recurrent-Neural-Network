{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nB4sbrU3WqFU",
    "outputId": "ec32f401-bd38-482d-fa7a-3e597fe3cfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jZJhFpnMr9If"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3xWOBZMyljq"
   },
   "source": [
    "## Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1Ajl-ce7BJc9"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('/content/drive/MyDrive/seq2seq/data_preprocessed_post_analysis1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWUXK2fU-3l2",
    "outputId": "1140d64b-7e01-40f4-965d-b56511c0be73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M73Ayaiv1fEx"
   },
   "outputs": [],
   "source": [
    "english_text_inp = '<start> ' + data_df['english_text'].astype(str)\n",
    "english_text_out = data_df['english_text'].astype(str) + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gtbZrAx21iIG"
   },
   "outputs": [],
   "source": [
    "data_df['english_inp'] = english_text_inp\n",
    "data_df['english_out'] = english_text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DZLgG-zV6I8J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data_df, test_size=0.1, random_state=33)\n",
    "train, test = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IJSMAGKC5Lng"
   },
   "outputs": [],
   "source": [
    "# we are doing the below step to add '<end>' to the tokenizer dictionary\n",
    "\n",
    "train.iloc[0]['english_inp'] = train.iloc[0]['english_inp'] + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2r7MYeLyx8zh"
   },
   "outputs": [],
   "source": [
    "tknizer_corr = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_corr.fit_on_texts(train['corrupted_text'].values)\n",
    "\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-qDy70uVjNy",
    "outputId": "9f9d2648-d50b-42e1-a05b-c64ad9e5711e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/seq2seq/tknizer_eng€']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tknizer_corr, '/content/drive/MyDrive/seq2seq/tknizer_corr')\n",
    "joblib.dump(tknizer_eng,  '/content/drive/MyDrive/seq2seq/tknizer_eng€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pC0IUPOCSG5P",
    "outputId": "72aef163-edaf-44c4-969c-1afc9653a782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993\n",
      "20105\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_corr=len(tknizer_corr.word_index.keys())\n",
    "print(vocab_size_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orEY2L-z7sz9"
   },
   "source": [
    "## Encoder Decoder with Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwrFQ5UhnesW",
    "outputId": "bd3aae86-d78e-48df-e06e-97ada93c33e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.7/dist-packages (1.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FFwMDGxIl4YD"
   },
   "outputs": [],
   "source": [
    "from nlpaug.util.file.download import DownloadUtil\n",
    "model_dir = '/content/'\n",
    "if not os.path.exists('/content/glove.6B'):\n",
    "  DownloadUtil.download_glove('glove.6B', '/content/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "haWOIlBToLdC"
   },
   "outputs": [],
   "source": [
    "\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "encoder_embedding_matrix = np.zeros((vocab_size_corr+1, 300))\n",
    "for word, i in tknizer_corr.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        encoder_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "decoder_embedding_matrix = np.zeros((vocab_size_eng+1, 300))\n",
    "for word, i in tknizer_eng.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        decoder_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s6DFJHWY7zka"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size = lstm_size\n",
    "\n",
    "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                    mask_zero=True, name=\"embedding_layer_encoder\",\n",
    "                     weights=[encoder_embedding_matrix], trainable=False\n",
    "                     )\n",
    "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\", \n",
    "                             activation ='tanh', kernel_regularizer=l2(1e-3)\n",
    "                             )\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "\n",
    "        #   This function takes a sequence input and the initial states of the encoder.\n",
    "        #   Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "        #   returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "\n",
    "        embedding_layer = self.embedding(input_sequence)\n",
    "\n",
    "        lstm_output, lstm_state_h, lstm_state_c = self.lstm(embedding_layer)\n",
    "        \n",
    "        return lstm_output, lstm_state_h, lstm_state_c\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "    #   '''\n",
    "    #   Given a batch size it will return intial hidden state and intial cell state.\n",
    "    #   If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "    #   '''\n",
    "        hidden_state = np.zeros((batch_size, self.lstm_size))\n",
    "        cell_state = np.zeros((batch_size, self.lstm_size))\n",
    "\n",
    "        return hidden_state, cell_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6d2Q6KFB5zDT"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "    super().__init__()  \n",
    "\n",
    "    self.scoring_function = scoring_function\n",
    "    self.att_units = att_units\n",
    "    \n",
    "    if self.scoring_function=='dot':\n",
    "      # Intialize variables needed for Dot score  function here\n",
    "      pass\n",
    "    \n",
    "    if scoring_function == 'general':\n",
    "      # Intialize variables needed for General score function here\n",
    "        self.w1 = tf.keras.layers.Dense(self.att_units)\n",
    "\n",
    "    elif scoring_function == 'concat':\n",
    "      # Intialize variables needed for Concat score function here\n",
    "        self.w11 = tf.keras.layers.Dense(self.att_units)\n",
    "        self.w21 = tf.keras.layers.Dense(self.att_units)\n",
    "        self.v = tf.keras.layers.Dense(1)\n",
    "  \n",
    "  \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    \n",
    "    if self.scoring_function == 'dot':\n",
    "        # Implement Dot score function here\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=-1)\n",
    "        score = tf.matmul(encoder_output,decoder_hidden_state)\n",
    "\n",
    "    elif self.scoring_function == 'general':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=-1)\n",
    "        score = tf.matmul(self.w1(encoder_output), decoder_hidden_state)\n",
    "\n",
    "    elif self.scoring_function == 'concat':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=1)\n",
    "        score = self.v(tf.nn.tanh(self.w11(decoder_hidden_state) + self.w21(encoder_output)))\n",
    "\n",
    "    weights = tf.nn.softmax(score,axis=1)\n",
    "    context_vector = weights * encoder_output\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    return context_vector, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9v7Bvpup8JBO"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "\n",
    "    super().__init__()\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "    self.tar_vocab_size = tar_vocab_size\n",
    "    self.att_units = att_units\n",
    "    self.score_fun = score_fun\n",
    "    self.input_length = input_length\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.dec_units = dec_units\n",
    "\n",
    "    self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                            mask_zero=True, name=\"embedding_layer_step_decoder\", \n",
    "                            weights=[decoder_embedding_matrix], trainable=False\n",
    "                            )\n",
    "    \n",
    "    self.lstm = LSTM(self.dec_units, return_state=True, return_sequences=True, name=\"One_Step_decoder_LSTM\",\n",
    "                         activation = 'tanh', kernel_regularizer=l2(1e-3)\n",
    "                         )\n",
    "\n",
    "    self.attention = Attention(self.score_fun, self.att_units)\n",
    "\n",
    "    self.dense = Dense(self.tar_vocab_size)\n",
    "\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    #     One step decoder mechanisim step by step:\n",
    "    #   A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "\n",
    "    # print(input_to_decoder.shape)\n",
    "    embedding_layer = self.embedding(input_to_decoder)\n",
    "\n",
    "\n",
    "    #   B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "    context_vector,attention_weights = self.attention(state_h, encoder_output)\n",
    "    context_vector = tf.expand_dims(context_vector, axis=1)\n",
    "\n",
    "    # print('embedding layer - ',embedding_layer.shape)\n",
    "    # print('attention - ', attention.shape)\n",
    "\n",
    "    #   C. Concat the context vector with the step A output\n",
    "    concat_layer = concatenate(inputs=[embedding_layer, context_vector])\n",
    "    #   D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "    lstm_out, state_hidden, state_cell = self.lstm(concat_layer, initial_state=[state_h, state_c])\n",
    "    lstm_out = tf.squeeze(lstm_out, axis=1)\n",
    "    # context_vector = tf.squeeze(context_vector, axis=1)\n",
    "    # states = [state_hidden, state_cell]\n",
    "    #   E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "    output = self.dense(lstm_out)\n",
    "    #   F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    return output, state_hidden, state_cell, attention_weights, context_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BSuLBoPH8_To"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.onestepdecoder = OneStepDecoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state):\n",
    "\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        all_outputs = tf.TensorArray(tf.float32, size=tf.shape(input_to_decoder)[1], name='output_arrays')\n",
    "\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        #Iterate till the length of the decoder input\n",
    "        for i in range(tf.shape(input_to_decoder)[1]):\n",
    "            # print(tf.reshape(input_to_decoder[:,i], [-1,1]))\n",
    "            # print(input_to_decoder[:].shape)\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.onestepdecoder(input_to_decoder[:,i:i+1], encoder_output, decoder_hidden_state, decoder_cell_state)\n",
    "\n",
    "            # Store the output in tensorarray\n",
    "            all_outputs = all_outputs.write(i, output)\n",
    "        \n",
    "        all_outputs = tf.transpose(all_outputs.stack(), [1,0,2])\n",
    "        # Return the tensor array\n",
    "        return all_outputs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YIxHKFZv9D3Y"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_encoder_len, vocab_decoder_len, embedding_dim, lstm_size, input_length, score_fun, att_units):\n",
    "    #Intialize objects from encoder decoder\n",
    "    super().__init__()\n",
    "    self.vocab_encoder_size = vocab_encoder_len\n",
    "    self.vocab_decoder_size = vocab_decoder_len\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self. lstm_size = lstm_size\n",
    "    self. input_length = input_length\n",
    "    self.socre_fun = score_fun\n",
    "    self.att_units = att_units\n",
    "    self.encoder = Encoder(self.vocab_encoder_size, self.embedding_dim , lstm_size,input_length)\n",
    "    self.decoder = Decoder(self.vocab_decoder_size, self.embedding_dim, input_length, lstm_size ,score_fun ,att_units)\n",
    "\n",
    "  \n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    initial_state=self.encoder.initialize_states(batch_size)\n",
    "    encoder_output,state_h,state_c=self.encoder(data[0],initial_state)\n",
    "\n",
    "\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    output=self.decoder(data[1],encoder_output, state_h, state_c)\n",
    "    # return the decoder output\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uOTDXTG28Jum"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_corr, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['corrupted_text'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_corr = tknizer_corr\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_corr.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU9rnqX38VZe",
    "outputId": "c2975e64-e757-4ad6-9501-28e60cee03be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50) (100, 50) (100, 50)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_corr, tknizer_eng, 50)\n",
    "validation_dataset  = Dataset(validation, tknizer_corr, tknizer_eng, 50)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=100)\n",
    "validation_dataloader = Dataloder(validation_dataset, batch_size=100)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3N3F4xG0H1Q4"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "# Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "def custom_lossfunction(targets,logits):\n",
    "\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    loss_ = loss_object(targets, logits)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZxaU4ShsqiFh"
   },
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch, learning_rate):\n",
    "  if epoch % 10 == 0:\n",
    "    learning_rate = learning_rate * 0.95\n",
    "    return learning_rate\n",
    "  else:\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekaAdW8M8VU0",
    "outputId": "af941c72-a19d-447b-d2ff-20d5d98889ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "129/129 [==============================] - 136s 969ms/step - loss: 1.7723 - val_loss: 1.5756\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 125s 970ms/step - loss: 1.4256 - val_loss: 1.3469\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 126s 977ms/step - loss: 1.1345 - val_loss: 1.0638\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 126s 976ms/step - loss: 0.8804 - val_loss: 0.8828\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 124s 963ms/step - loss: 0.7117 - val_loss: 0.7548\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 123s 957ms/step - loss: 0.6110 - val_loss: 0.6664\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 124s 964ms/step - loss: 0.5194 - val_loss: 0.6040\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 124s 963ms/step - loss: 0.4696 - val_loss: 0.5588\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 124s 959ms/step - loss: 0.4270 - val_loss: 0.5544\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 122s 948ms/step - loss: 0.4047 - val_loss: 0.5646\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 124s 961ms/step - loss: 0.2391 - val_loss: 0.3211\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 124s 960ms/step - loss: 0.1756 - val_loss: 0.3006\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 122s 948ms/step - loss: 0.1589 - val_loss: 0.2869\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 122s 949ms/step - loss: 0.1482 - val_loss: 0.2772\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 121s 936ms/step - loss: 0.1397 - val_loss: 0.2690\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 122s 948ms/step - loss: 0.1327 - val_loss: 0.2647\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 120s 933ms/step - loss: 0.1267 - val_loss: 0.2599\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 122s 944ms/step - loss: 0.1213 - val_loss: 0.2552\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 122s 947ms/step - loss: 0.1158 - val_loss: 0.2497\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 120s 930ms/step - loss: 0.1111 - val_loss: 0.2468\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 120s 929ms/step - loss: 0.1061 - val_loss: 0.2436\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 121s 939ms/step - loss: 0.1020 - val_loss: 0.2468\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 121s 934ms/step - loss: 0.0899 - val_loss: 0.2320\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 122s 946ms/step - loss: 0.0855 - val_loss: 0.2337\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 120s 931ms/step - loss: 0.0827 - val_loss: 0.2328\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 120s 933ms/step - loss: 0.0819 - val_loss: 0.2328\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 121s 941ms/step - loss: 0.0817 - val_loss: 0.2328\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 120s 931ms/step - loss: 0.0817 - val_loss: 0.2328\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 123s 956ms/step - loss: 0.0817 - val_loss: 0.2328\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 120s 930ms/step - loss: 0.0817 - val_loss: 0.2328\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  6753000   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  2899891   \n",
      "=================================================================\n",
      "Total params: 9,652,891\n",
      "Trainable params: 2,722,891\n",
      "Non-trainable params: 6,930,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "embedding_dim = 300\n",
    "lstm_size = 300\n",
    "input_length = 50\n",
    "score_fun = 'concat'\n",
    "att_units = 32\n",
    "batch_size = 100\n",
    "\n",
    "model = encoder_decoder(vocab_size_corr + 1, vocab_size_eng + 1, embedding_dim, lstm_size, input_length, score_fun, att_units)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
    "\n",
    "# log_dir=\"model_concat1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.compat.v1.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads =True)\n",
    "\n",
    "learningratescheduler = LearningRateScheduler(learning_rate_scheduler)\n",
    "\n",
    "train_steps=train.shape[0]//100\n",
    "valid_steps=validation.shape[0]//100\n",
    "\n",
    "model_history1 = model.fit(x = train_dataloader, steps_per_epoch =train_steps, epochs=30, validation_data=validation_dataloader, \n",
    "              validation_steps = valid_steps,\n",
    "              callbacks =[\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                            monitor='val_loss', factor=0.2, patience=1),\n",
    "                    #   tensorboard_callback,\n",
    "                      learningratescheduler\n",
    "          ]\n",
    "              )\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xnAkV_-1-Q-c"
   },
   "outputs": [],
   "source": [
    "model.save_weights('content/drive/MyDrive/seq2seq/simple_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvKYUsSP9B0P",
    "outputId": "7d91706d-30f7-46cd-bd4c-5c23a7134482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  6753000   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  2899891   \n",
      "=================================================================\n",
      "Total params: 9,652,891\n",
      "Trainable params: 2,722,891\n",
      "Non-trainable params: 6,930,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "RfKEgnsIgzqG",
    "outputId": "b489ade2-0704-4c86-deb7-b4cfc1ceb567"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history1.history['loss'])\n",
    "plt.plot(model_history1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pCeOKH5xXEzY"
   },
   "outputs": [],
   "source": [
    "#  Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R6WFxByfXEu5"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence, target, model, plot_attention_flag):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "            predictions, input_h,input_c, attention_weights, _ = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "            Save the attention weights\n",
    "            And get the word using the tokenizer(word index) and then store it in a string.\n",
    "    E. Call plot_attention(#params)\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "\n",
    "    attention_plot = np.zeros((50, 50))\n",
    "    inp_seq = tknizer_corr.texts_to_sequences([input_sentence])\n",
    "    inp_seq = pad_sequences(inp_seq,padding='post',maxlen=50)\n",
    "\n",
    "    encoder = Encoder(inp_vocab_size=vocab_size_corr, embedding_size=100, lstm_size=256, input_length=50)\n",
    "    states = encoder.initialize_states(32)\n",
    "\n",
    "    en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq), states)\n",
    "    cur_vec = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
    "    pred = []\n",
    "    \n",
    "    #Here 50 is the max_length of the sequence\n",
    "    for i in range(50):\n",
    "        infe_output, state_h, state_c, attention_weights, _ = model.layers[1].layers[0](cur_vec,en_outputs,state_h,state_c)\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[i] = attention_weights.numpy()\n",
    "        cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "        if cur_vec[0][0]:\n",
    "          pred.append(tknizer_eng.index_word[cur_vec[0][0]])\n",
    "        else: \n",
    "          continue\n",
    "        if(pred[-1]=='<end>'):\n",
    "            break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "    attention_plot = attention_plot[:len(translated_sentence.split(' ')),\n",
    "                                    :len(input_sentence.split(' '))]\n",
    "\n",
    "    if plot_attention_flag:\n",
    "        plot_attention(attention_plot, input_sentence.split(' '), translated_sentence.split(' '))    \n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmh7xX2-O4gn",
    "outputId": "040684ea-39f8-4278-ee97-4b4ca57d9650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual  : yeah said going with wawa still must take mrt sigh\n",
      "predicted: yes jos called that like raining going to see my handphone girl <end>\n",
      "bleu score: 0.537284965911771\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : crazy still buy wine at home got a bottle of wine already\n",
      "predicted: crazy still buy wine at home got a bottle of wine <end>\n",
      "bleu score: 0.9131007162822624\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : haha okay how late i go to buy tickets first\n",
      "predicted: haha okay so late i go to buy tickets first <end>\n",
      "bleu score: 0.7071067811865475\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : where are you all\n",
      "predicted: where are you all <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i will call you how would i know what time\n",
      "predicted: i will be late for meeting probably 10 mins <end>\n",
      "bleu score: 0.3653166213293175\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi jordan where are you lanz here 26 work\n",
      "predicted: hi roy introduce please please sms at 016 5419814 <end>\n",
      "bleu score: 0.5773502691896257\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : anyone knows where got sell nice cute good quality bathing towels in town\n",
      "predicted: just curious to see what you define go too my have happy going for you <end>\n",
      "bleu score: 0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : fast today my friend have to work tomorrow\n",
      "predicted: fast today my friend have to work tomorrow <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : what about leona i am fine with anything i am free but not too early\n",
      "predicted: what is leona why and go to be really with me and not come <end>\n",
      "bleu score: 0.6807097238524916\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : happy belated birthday yun y hope you had a wonderful day and remain this sweet and happy always hugs j ayin here by the way\n",
      "predicted: sorry for the reply they is is good too so were i a new time but so is too <end>\n",
      "bleu score: 0.41535885426035796\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : we are near coca already\n",
      "predicted: we are at coca already <end>\n",
      "bleu score: 0.7952707287670506\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : 8332 2650 6006 please buy 2 big and 2 small for these 3 ok\n",
      "predicted: please want to send me to the after of right you tonight <end>\n",
      "bleu score: 0.4548019047027907\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : no need\n",
      "predicted: no table <end>\n",
      "bleu score: 0.8408964152537145\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : ok sian right i have to go back to the whole days what are you taking and how is your timetable anyway you think i should bring it to see doctor my sister says it will have disease\n",
      "predicted: ok sian right i have to go back to the whole days what are you taking and how is your timetable anyway you think i should bring it to see doctor my sister says it will have disease <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i am with my brother but later he is going out\n",
      "predicted: i am still at my friend is place where r u <end>\n",
      "bleu score: 0.43668354428478123\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hello huiqi suggested we all sit together in tomorrow lecture so that we can discuss about the term paper\n",
      "predicted: hello huiqi suggested we all sit together in tomorrow lecture so that we are you need to watch <end>\n",
      "bleu score: 0.6576861292902106\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : faint you want to look after joan is guinea pigs friday to monday she is going to genting\n",
      "predicted: yun driving that late can be so with me how is you doing <end>\n",
      "bleu score: 0.42631962149316155\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i have asked already ron can leona can not xf and ben not confirmed then why is the dinner not confirmed yet by the way shuhui saw nemo already\n",
      "predicted: i have a little angel flying around with a hammer each person he hits gets a little bit of my love and concern so think so <end>\n",
      "bleu score: 0.23224216572375114\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i think you should keep your hair you can go survey all of your friends hee i was thinking of toni and guys because my sister wants to dye her hair\n",
      "predicted: i think you should keep your hair you can go survey all of your friends hee i got to talk to return books <end>\n",
      "bleu score: 0.5158150905431749\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : okie really sorry\n",
      "predicted: okie really sorry <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : we must try to bid for the same tutorial group\n",
      "predicted: we must try to bid for the same tutorial group <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : haha use your imagination see you tomorrow\n",
      "predicted: haha use your imagination see you tomorrow <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : my phone has no battery pick me up at 2pm at drive have you all eaten faint here is using huixin is phone\n",
      "predicted: my sister has student price i do not know i am going now i also that are going to tv <end>\n",
      "bleu score: 0.4840116640647708\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : we are at row 1 on left\n",
      "predicted: we are at row 1 on left <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : got how many brand and model\n",
      "predicted: got how many brand and model <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i see i thought you go with xf joking\n",
      "predicted: i think i will be going for my friends <end>\n",
      "bleu score: 0.6865890479690392\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : we must try to bid for the same tutorial group\n",
      "predicted: we must try to bid for the same tutorial group <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : ok see you\n",
      "predicted: ok see you <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : do you want to meet up tomorrow\n",
      "predicted: do you want to meet up tomorrow <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : today i did not know you have not eaten yet if not i would not have finished up your brownie thanks for the brownie anyway\n",
      "predicted: today i did not know you have not eaten yet if not i would not have finished up your brownie <end>\n",
      "bleu score: 0.7788007830714049\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i am still having breakfast if you reach there first can you help me and rebecca reserve seats\n",
      "predicted: i am still having breakfast if you reach there first can you help me and rebecca reserve seats <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : frog wah okay you decide first\n",
      "predicted: nesh can you intro yourself <end>\n",
      "bleu score: 0.5475182535069453\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : really haiz thinks he is crazy too\n",
      "predicted: really haiz thinks he is crazy <end>\n",
      "bleu score: 0.846481724890614\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hmm if it was me i would also feel like going but you still need him for your final year project right then maybe it is good to suck up to him a little did he say where the place was and when\n",
      "predicted: hmm if it was me i would also feel like going but you still need him for your final year project right then maybe it is good to suck up to him a little did he say where the place was and when <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi everyone\n",
      "predicted: hi everyone <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : dinner still on\n",
      "predicted: dinner still on <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i am dying of boredom at home i need a job any recommendations\n",
      "predicted: i am going to bug coming to send you now at here <end>\n",
      "bleu score: 0.3572281085191041\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : wow rot at home haha raining good weather to sleep haha\n",
      "predicted: wow rot at home haha you are watching <end>\n",
      "bleu score: 0.355310106137518\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : oh yes doing the accounting tutorial now i think bukit panjang is going to rain soon what time have you decided to go out\n",
      "predicted: oh yes that is my wooden now the me not good will be more months reply you all all and are only and <end>\n",
      "bleu score: 0.31594960344453354\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : joey hi care to introduce now\n",
      "predicted: hi care to chat <end>\n",
      "bleu score: 0.42888194248035344\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i cannot remember what time is my lesson i will confirm with you again when i go home ok\n",
      "predicted: hmm i do not know maybe she never am going to be long to to yet later <end>\n",
      "bleu score: 0.43781869404573154\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : then what time are you coming home\n",
      "predicted: then what time are you coming home <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : oh no that means you are not coming for statistics then you can not help me print because i need it right after that okay all the best for you test do not worry\n",
      "predicted: oh no i am not online did u add the wrong person ivle got a girl in math major also same surname the name did know do not know that was take was laugh <end>\n",
      "bleu score: 0.345566617029635\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : james i will be working out at the gym what time will you be there teach me how to use the machines\n",
      "predicted: james i will be working out at the gym what time will you be there teach me how to use the machines <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi merina it is nice to chat with you your hand phone number please what is your race\n",
      "predicted: hi it is kate how is your evening i hope i change i you have you have <end>\n",
      "bleu score: 0.4321219739263302\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : no took a break for a few days hehe\n",
      "predicted: no took a break for a few days hehe <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi joey\n",
      "predicted: hi tina <end>\n",
      "bleu score: 0.8408964152537145\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hey girl how are you hope you are well i and del are back again long time no see give me a call some time from lucy\n",
      "predicted: hey yijue how are you getting there later we are meeting a tomorrow at the at at saturday what is just going now want to meet you <end>\n",
      "bleu score: 0.16805936904720342\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i woke up already now i am still lying on my bed\n",
      "predicted: i reach already call me at you lesser you also <end>\n",
      "bleu score: 0.5475182535069453\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : leave you there\n",
      "predicted: hi can you <end>\n",
      "bleu score: 0.7598356856515925\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : yes that was what i had in mind going out with my god sister to watch a movie i have not seen one since my birthday last month well hope you enjoy yourself take care\n",
      "predicted: no not nice to to shall i call university got at the same and you so how is here for you or not only sure you see how there you girls to take <end>\n",
      "bleu score: 0.5872095883600223\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : tomorrow i cannot eat ramen already i have to stay at home and wait for that dvd player to come sad we go on thur ok\n",
      "predicted: tomorrow i cannot i meet so then never end for i am 2 a bit on the only not you have a very fun <end>\n",
      "bleu score: 0.16953148353536282\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : yes sure evening right\n",
      "predicted: yes sure evening right <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : have not slept yet how have you been recently how is orientation week\n",
      "predicted: have not ask yet because have not decided on which package <end>\n",
      "bleu score: 0.36408617932284865\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : if you are in town i take taxi myself\n",
      "predicted: if you are in town i take taxi myself <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hello i am back just got back last night looking forward to seeing you all i will call you soon elaine\n",
      "predicted: haha i am going to buy sandals how to go queensway any cute hunks around wow so late <end>\n",
      "bleu score: 0.26635910283496855\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : anyway i thought she was already in quite a down state so how is she now\n",
      "predicted: anyway i thought she was already in quite a down state so how is she now <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : oh i can meet you outside\n",
      "predicted: yes i do not know why <end>\n",
      "bleu score: 0.6389431042462724\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hey it would be great if you could loan me your stuff\n",
      "predicted: he it celine you have not not i want to go <end>\n",
      "bleu score: 0.5962494769762219\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : are you sure you do not bluff me i do not like to take photos\n",
      "predicted: are you going for class outing this saturday west coast can rent roller blades or not haha <end>\n",
      "bleu score: 0.32406944672724197\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i am in imperialmusic listening to the weirdest track ever by leafcutter john sounds like insects being molested and someone plumbing remixed by evil men on acid\n",
      "predicted: i am in imperialmusic listening to the weirdest track ever by leafcutter john sounds like insects being molested and get plumbing <end>\n",
      "bleu score: 0.6828335704817795\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : oh again wow you are like very nice for these few weeks\n",
      "predicted: oh okay nevermind you enjoy yourself i message you again <end>\n",
      "bleu score: 0.6059285518620335\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hey i can not stay out late tomorrow night\n",
      "predicted: hey i can not stay out late tomorrow night <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hmm i am watching with my friends already it is embarrassing\n",
      "predicted: hmm i am at the sub bus already thanks <end>\n",
      "bleu score: 0.2842202242491899\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : kay see you hope there is space\n",
      "predicted: kay can you with yourself <end>\n",
      "bleu score: 0.5330859115179258\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : pick me up at 6 same place car park there\n",
      "predicted: help me collect the clothes going to rain <end>\n",
      "bleu score: 0.4630777161991027\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi introduce please\n",
      "predicted: hi lady please <end>\n",
      "bleu score: 0.9036020036098448\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hello hello hi lou sorry it took so long to reply i left mobile at friends in lancaster just got it back anyway i am sorry i could not make it to your birthday too honey\n",
      "predicted: hello hello nice lou on the way you that she will be turn if again i am going to drop pretty no you have something to to see you can have want to get soon <end>\n",
      "bleu score: 0.32006401936121315\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : haha never cut then do not return you haha ok i then see you there slightly before 12 45 ok good night\n",
      "predicted: haha no study science is good it is where the most jobs are haha so will see you around in nus <end>\n",
      "bleu score: 0.3149557118540763\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : what are you up to i thought you were going to call me text back love ok\n",
      "predicted: you do not know i think i stays working amk about home there never <end>\n",
      "bleu score: 0.4962064288956292\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : you will be at around what area\n",
      "predicted: you are free outside what on time <end>\n",
      "bleu score: 0.7311104457090247\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : er i never bring wallet mac muffin can or not\n",
      "predicted: er i can only make so there i just going <end>\n",
      "bleu score: 0.427287006396234\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i see sign why do you never ask me along i am so bored at home\n",
      "predicted: i know you should keep more much i can go to see one is in the <end>\n",
      "bleu score: 0.7071067811865476\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : you wake up already\n",
      "predicted: you wake up already <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : do you want to go swimming\n",
      "predicted: do you want to to swimming <end>\n",
      "bleu score: 0.537284965911771\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : yeap i will call you in a while i am booking my lessons online\n",
      "predicted: yeap i will i see the from for the bugis <end>\n",
      "bleu score: 0.21763141204756337\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : what about leona i am fine with anything i am free but not too early\n",
      "predicted: what is leona why and go to be really with me and not come <end>\n",
      "bleu score: 0.6807097238524916\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : are you male or female\n",
      "predicted: are you driving there tomorrow <end>\n",
      "bleu score: 0.5623413251903491\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i also just came back from collecting my drawer just now serangoon has a jam\n",
      "predicted: i just got accepted into nus arts really really really thank god for the miracle <end>\n",
      "bleu score: 0.6042750794713536\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : ok i will tell you if i am going\n",
      "predicted: ok i will tell you if i am going <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : what about leona i am fine with anything i am free but not too early\n",
      "predicted: what is leona why and go to be really with me and not come <end>\n",
      "bleu score: 0.6807097238524916\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hey girl what message did you send just now\n",
      "predicted: hi happy new year how have you been <end>\n",
      "bleu score: 0.5247357977607321\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : ok\n",
      "predicted: ok <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : my jobs have less than one month unless it has a very good pay haha well go to sleep good night my dear see you one monday\n",
      "predicted: my jobs is at 2 ok you the looks good then is also you have me your out if her boyfriend i am the hall self you <end>\n",
      "bleu score: 0.29050808466714345\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : exercise till what time after exercise fat\n",
      "predicted: exercise till what time after exercise fat <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : i see sign why do you never ask me along i am so bored at home\n",
      "predicted: 1st week sports unlimited extreme camp extra curriculum activity 2nd hall camp <end>\n",
      "bleu score: 0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : really oh nearer to my workplace and stella chose one\n",
      "predicted: ouch oh mei is my going going on be chat <end>\n",
      "bleu score: 0.668740304976422\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : nokia 7250 without trade in is 719\n",
      "predicted: nokia 7250 without trade in is 719 <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : haha okay how late i go to buy tickets first\n",
      "predicted: haha okay so late i go to buy tickets first <end>\n",
      "bleu score: 0.7071067811865475\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi everyone\n",
      "predicted: hi everyone <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : anyone has a cultural or ethnic top i can borrow\n",
      "predicted: anyone has a cultural or ethnic top <end>\n",
      "bleu score: 0.6514390575310556\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hmm both of my friends coming are guys but i do not dance they do actually i am there for the drinks only so how\n",
      "predicted: hmm both why so you are that great the new time i am sure not know i to go for you soon <end>\n",
      "bleu score: 0.397992630283179\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : zping is at her house so she is not free then is 7 plus at amk central okay for you\n",
      "predicted: look at the taka to be the immediately we to meet you after once hehe <end>\n",
      "bleu score: 0.4329820146406897\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : anyone care for chat\n",
      "predicted: anyone care for chat <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : yeah i am too heart broken scattered everywhere remember that is why i woke up late haha no i am heart broken but no course only 2 days what are you doing now\n",
      "predicted: yes i am whoops i do not know what colour i will pass a place at 2 only haha when are you going shopping with you i help to know you <end>\n",
      "bleu score: 0.3590192728267748\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : eating at far east going to drink coffee now\n",
      "predicted: eating at far east going to drink coffee now <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : yes but its really tough trying to learn it by myself with only books but i want a head start for next year so when is your overseas trip\n",
      "predicted: yes grounded oh clubbing but i think it is not much cheaper i maybe to reply you not call me a number i have not changed to see then <end>\n",
      "bleu score: 0.30470915491420003\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hmm nevermind then get from you another day\n",
      "predicted: hmm nevermind you get then go to <end>\n",
      "bleu score: 0.5091996654452335\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : hi ric i am agnes where are you from\n",
      "predicted: hi ric i am agnes where are you from <end>\n",
      "bleu score: 1.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "actual  : what award haha okay not bad still got award then science got win anything i am at school of computing now if you are free you can come and look for me\n",
      "predicted: just went to go gym by that i can not help it i said he can not my parents to go for monday and see the suntec at home <end>\n",
      "bleu score: 0.6081508215297238\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "bleu_score = list()\n",
    "random_numbers = np.random.randint(1, len(test), 100)\n",
    "for i in (random_numbers):\n",
    "\n",
    "    actual_ = test.iloc[i]['english_text']\n",
    "    pred_ = predict(test.iloc[i]['corrupted_text'], actual_, model, plot_attention_flag=False)\n",
    "\n",
    "    reference = [actual_.split()]\n",
    "    candidate = pred_.split()[:-1]\n",
    "\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    bleu_score.append(score)\n",
    "\n",
    "    print('actual  :', actual_)\n",
    "    print('predicted:', pred_)\n",
    "    print('bleu score:', score)\n",
    "    print()\n",
    "    print('-' * 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vukT1NDhXEkP",
    "outputId": "cc1dc7c6-12af-43a9-87e8-3638f3290b21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [1:12:32<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_sentences = list()\n",
    "bleu_score = list()\n",
    "for i in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "\n",
    "    actual_ = data_df.iloc[i[0]]['english_text']\n",
    "    pred_ = predict(data_df.iloc[i[0]]['corrupted_text'], actual_, model, plot_attention_flag=False)\n",
    "\n",
    "    reference = [actual_.split()]\n",
    "    candidate = pred_.split()[:-1]\n",
    "\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    bleu_score.append(score)\n",
    "    predicted_sentences.append(' '.join(candidate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QeYATjOBePo-"
   },
   "outputs": [],
   "source": [
    "data = data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "kDbfM-vjDWvV",
    "outputId": "440d464f-d749-4dbd-a5f7-7b59914d4b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yaep you reaching we oredrde some durian pastr...</td>\n",
       "      <td>yeap you reaching we ordered some durian pastr...</td>\n",
       "      <td>&lt;start&gt; yeap you reaching we ordered some duri...</td>\n",
       "      <td>yeap you reaching we ordered some durian pastr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never mind this one it s for aostkalia but i w...</td>\n",
       "      <td>never mind this one it is for australia but i ...</td>\n",
       "      <td>&lt;start&gt; never mind this one it is for australi...</td>\n",
       "      <td>never mind this one it is for australia but i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text  ...                                        english_out\n",
       "0  yaep you reaching we oredrde some durian pastr...  ...  yeap you reaching we ordered some durian pastr...\n",
       "1  never mind this one it s for aostkalia but i w...  ...  never mind this one it is for australia but i ...\n",
       "\n",
       "[2 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "U5nJFGRlDX6T"
   },
   "outputs": [],
   "source": [
    "data['predicted_sentences'] = predicted_sentences\n",
    "data['bleu_score'] = bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "85TtWsn7DvE6",
    "outputId": "981d9d5b-4f60-49ae-8120-09bd5633b92b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "      <th>predicted_sentences</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yaep you reaching we oredrde some durian pastr...</td>\n",
       "      <td>yeap you reaching we ordered some durian pastr...</td>\n",
       "      <td>&lt;start&gt; yeap you reaching we ordered some duri...</td>\n",
       "      <td>yeap you reaching we ordered some durian pastr...</td>\n",
       "      <td>have you finished any exercise yet what is lik...</td>\n",
       "      <td>0.547518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never mind this one it s for aostkalia but i w...</td>\n",
       "      <td>never mind this one it is for australia but i ...</td>\n",
       "      <td>&lt;start&gt; never mind this one it is for australi...</td>\n",
       "      <td>never mind this one it is for australia but i ...</td>\n",
       "      <td>never mind this one it is for australia but i ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      corrupted_text  ... bleu_score\n",
       "0  yaep you reaching we oredrde some durian pastr...  ...   0.547518\n",
       "1  never mind this one it s for aostkalia but i w...  ...   1.000000\n",
       "\n",
       "[2 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1UmDEEFHEWYS"
   },
   "outputs": [],
   "source": [
    "# saving the file to disk\n",
    "# commenting the below code so to change data whenever needed\n",
    "data.to_csv('/content/drive/MyDrive/seq2seq/data_score_post_analysis1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "4M2jHLp14i0F"
   },
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09kMlR68gNCz",
    "outputId": "23c1a2eb-4909-4889-f19f-50c97fb6f62f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [06:07<00:00,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_sentences = list()\n",
    "bleu_score = list()\n",
    "for i in tqdm(test.iterrows(), total=len(test)):\n",
    "\n",
    "    actual_ = test.iloc[i[0]]['english_text']\n",
    "    pred_ = predict(test.iloc[i[0]]['corrupted_text'], actual_, model, plot_attention_flag=False)\n",
    "\n",
    "    reference = [actual_.split()]\n",
    "    candidate = pred_.split()[:-1]\n",
    "\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    bleu_score.append(score)\n",
    "    predicted_sentences.append(' '.join(candidate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "HiEkZODagNC0"
   },
   "outputs": [],
   "source": [
    "test_data = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "-yYqRy-2gNC0",
    "outputId": "808849ae-c55b-4156-f138-48aaedd0022c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>yun you knwo the tsep by stpe guied obok we wr...</td>\n",
       "      <td>yun you know the step by step guide book we we...</td>\n",
       "      <td>&lt;start&gt; yun you know the step by step guide bo...</td>\n",
       "      <td>yun you know the step by step guide book we we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14926</td>\n",
       "      <td>hii are you girl nor boy</td>\n",
       "      <td>hi are you girl or boy</td>\n",
       "      <td>&lt;start&gt; hi are you girl or boy</td>\n",
       "      <td>hi are you girl or boy &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ...                                        english_out\n",
       "0  12346  ...  yun you know the step by step guide book we we...\n",
       "1  14926  ...                       hi are you girl or boy <end>\n",
       "\n",
       "[2 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fUz7hnJ8gNC0"
   },
   "outputs": [],
   "source": [
    "test_data['predicted_sentences'] = predicted_sentences\n",
    "test_data['bleu_score'] = bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "fRpGPOoVgNC1",
    "outputId": "041d44d8-376b-48db-a9d1-0e2fc1fc3432"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>corrupted_text</th>\n",
       "      <th>english_text</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "      <th>predicted_sentences</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>yun you knwo the tsep by stpe guied obok we wr...</td>\n",
       "      <td>yun you know the step by step guide book we we...</td>\n",
       "      <td>&lt;start&gt; yun you know the step by step guide bo...</td>\n",
       "      <td>yun you know the step by step guide book we we...</td>\n",
       "      <td>yun you know the step by step guide book we we...</td>\n",
       "      <td>0.881774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14926</td>\n",
       "      <td>hii are you girl nor boy</td>\n",
       "      <td>hi are you girl or boy</td>\n",
       "      <td>&lt;start&gt; hi are you girl or boy</td>\n",
       "      <td>hi are you girl or boy &lt;end&gt;</td>\n",
       "      <td>what are you up tonight</td>\n",
       "      <td>0.460406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ... bleu_score\n",
       "0  12346  ...   0.881774\n",
       "1  14926  ...   0.460406\n",
       "\n",
       "[2 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "D3KXQ2VHgNC1"
   },
   "outputs": [],
   "source": [
    "# saving the file to disk\n",
    "# commenting the below code so to change data whenever needed\n",
    "test_data.to_csv('/content/drive/MyDrive/seq2seq/test_data_score_post_analysis1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EncoderDecoderWithAttentionMechanism.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
